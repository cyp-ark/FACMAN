{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7a46e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from influxdb_client import InfluxDBClient\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "client = InfluxDBClient(\n",
    "    url=os.getenv(\"INFLUXDB_URL\"),\n",
    "    token=os.getenv(\"INFLUXDB_TOKEN\"),\n",
    "    org=os.getenv(\"INFLUXDB_ORG\"),\n",
    ")\n",
    "query_api = client.query_api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8509bb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain.agents import Tool\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[str], add_messages]\n",
    "    db_output: list\n",
    "    next_inspection: list\n",
    "    \n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c2b27f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_tool(process_id):\n",
    "    \"\"\"InfluxDB에서 프로세스 ID에 대한 로그를 조회합니다.\"\"\"\n",
    "    query = f'''\n",
    "    from(bucket: \"{process_id}_status\")\n",
    "    |> range(start: -1h)\n",
    "    |> filter(fn: (r) => r._measurement == \"status_log\")\n",
    "    '''\n",
    "    try:\n",
    "        tables = query_api.query(query)\n",
    "        logs = []\n",
    "        for table in tables:\n",
    "            for record in table.records:\n",
    "                logs.append(f\"{record.get_time()}: {record.get_value()}\")\n",
    "        \n",
    "        if not logs:\n",
    "            # 검색 결과가 없는 경우\n",
    "            if \"-\" in process_id:\n",
    "                return f\"라인 ID '{process_id}'에 대한 로그가 없습니다.\"\n",
    "            else:\n",
    "                return f\"프로세스 ID '{process_id}'에 대한 로그가 없습니다.\"\n",
    "        output = \"\\n\".join(logs)\n",
    "        return {\"message\": [output]}\n",
    "    except Exception as e:\n",
    "        return f\"로그 조회 중 오류 발생: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3eff0561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10eda8990>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "tool = Tool(\n",
    "    name=\"query_tool\",\n",
    "    func=query_tool,\n",
    "    description=\"\"\"Get recent status logs from InfluxDB for the given process_id or line_id.\n",
    "        The function returns the most recent status logs from the last hour.\n",
    "        Input should be a process ID (e.g., 'P1') or a line ID (e.g., 'P1-A').\n",
    "        Process ID is used to query by process_id field, while input with hyphen like 'P1-A' is used to query by line_id field.\n",
    "        \"\"\")\n",
    "tools = [tool]\n",
    "tool_node = ToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41798a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d5e448b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10eda8990>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GENERATE_SYSTEM_TEMPLATE = \"\"\"\n",
    "You are a database inspection assistant. You will be given a list of database queries and their results. Your task is to analyze the results and provide insights or suggestions for further actions.\"\"\"\n",
    "GENERATE_USER_TEMPLATE = \"\"\"\n",
    "You are a process monitoring assistant.\n",
    "Your job is to analyze process logs and help diagnose issues.\n",
    "\n",
    "When logs show errors, timeouts, or abnormal patterns, you can:\n",
    "1. Request more information about specific processes\n",
    "2. Send maintenance commands when necessary\"\"\"\n",
    "\n",
    "\n",
    "def supervisor(state: State):\n",
    "    msgs = [\n",
    "        (\"system\", GENERATE_SYSTEM_TEMPLATE),\n",
    "        (\"user\", GENERATE_USER_TEMPLATE)\n",
    "    ]\n",
    "    prompt = ChatPromptTemplate.from_messages(msgs)\n",
    "    response = llm_with_tools.invoke(\n",
    "        prompt.format_prompt(messages=state[\"messages\"]),\n",
    "    )\n",
    "    outputs = []\n",
    "    outputs.append(\n",
    "        AIMessage(\n",
    "            content=response.content,\n",
    "        )\n",
    "    )\n",
    "    return {\"messages\": outputs}\n",
    "\n",
    "graph_builder.add_node(\"supervisor\", supervisor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4af75129",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.add_edge(START, \"supervisor\")\n",
    "graph_builder.add_edge(\"supervisor\", END)\n",
    "graph_builder.add_conditional_edges(\"supervisor\", tools_condition)\n",
    "graph_builder.add_edge(\"tools\", \"supervisor\")\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "#graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13fe5399",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_graph_updates(user_input: str):\n",
    "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}): # graph 노드 호출 결과 받아옴\n",
    "        for value in event.values():\n",
    "            print(value, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb00e92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content=\"Please provide the specific process or line IDs whose logs you would like me to analyze, along with any recent logs or patterns you've observed. If there are specific errors or abnormalities, please include those details as well.\", additional_kwargs={}, response_metadata={}, id='a925d6c7-159e-4f7a-acda-3d7ad50c538b')]} \n",
      "\n",
      "{'messages': [AIMessage(content='Please provide the list of database queries and their results so I can analyze them for any issues or abnormal patterns.', additional_kwargs={}, response_metadata={}, id='18992eee-f87a-4ce2-867d-afc4270550c5')]} \n",
      "\n",
      "{'messages': [AIMessage(content='Please provide the specific process logs you would like me to analyze for errors, timeouts, or abnormal patterns.', additional_kwargs={}, response_metadata={}, id='e0b88f66-d0d0-4172-804f-43f5192fa6d3')]} \n",
      "\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    try:\n",
    "        user_input = input()\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb00f59d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
